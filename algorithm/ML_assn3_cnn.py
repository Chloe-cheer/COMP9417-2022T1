# -*- coding: utf-8 -*-
"""MLproj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SBfvNizBpxdYqOpQjhNgueqIp8kBAWdV
"""

import os
from typing import Any, Dict, List, Optional, Tuple
import torch
import sklearn.metrics as metrics
import numpy as np
import sys
import matplotlib.pyplot as plt
import statistics
# import tensorflow as tf
import torch.optim as optim
from torch import nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
import time
import datetime


# from algorithm.modules import UNet

# from google.colab import drive
# !unzip /content/drive/MyDrive/Colab\ Notebooks/MLproj/X_train_scaled.zip -d "/content"

# Commented out IPython magic to ensure Python compatibility.
# %cp ./drive/MyDrive/Colab\ Notebooks/MLproj/y_train.npy ./

# CONFIGS
base_path = "../input/"

x_train_path = base_path+"X_train_chunks/"
y_train_path = base_path+"y_train.npy"

split_ratio = "8:0:2" # train:val:test
use_full_dataset_to_train_and_val = False
batch_size = 1

split_ratio_lst = list(map(lambda x: int(x), split_ratio.split(":")))
if use_full_dataset_to_train_and_val:
    split_ratio_lst.remove(0)
split_ratio_lst_total = sum(split_ratio_lst)
data_size = 858
split_sizes = [int(data_size*(r/split_ratio_lst_total)) for r in split_ratio_lst]
split_sizes[-1] += data_size - sum(split_sizes)

print(f"split_sizes are {split_sizes}")

class TransformTensorDataset(Dataset):
    """TensorDataset with support of transforms.
    """
    def __init__(self, tensors, transform=None):
        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)
        self.tensors = tensors
        self.transform = transform

    def __getitem__(self, index):
        x = self.tensors[0][index]

        if self.transform:
            x = self.transform(x)

        y = self.tensors[1][index]

        return x, y

    def __len__(self):
        return self.tensors[0].size(0)

def load_X() -> Any:
    X = None
    for i in range(20):
        if X is None:
            X = np.load(x_train_path+f"X_train_scaled_{i:02d}.npy")
        else:
            X = np.concatenate((X, np.load(x_train_path+f"X_train_scaled_{i:02d}.npy")), axis=0)
    return X

X = load_X()
y = np.load(y_train_path)

print(X.shape)

full_dataset = TransformTensorDataset([torch.tensor(X), torch.tensor(y)])

if not use_full_dataset_to_train_and_val:
    validation = False
    if len(split_sizes) == 3 and split_sizes[1] != 0:
        data_train, data_val, data_test = random_split(full_dataset, split_sizes)
        validation = True
    else:
        if len(split_sizes) == 3:
            split_sizes.remove(0)
        data_train, data_test = random_split(full_dataset, split_sizes)

    train_dataloader = DataLoader(data_train, shuffle=True, batch_size=batch_size)

    if validation:
        val_dataloader = DataLoader(data_val, shuffle=False, batch_size=batch_size)

    test_dataloader = DataLoader(data_test, shuffle=False, batch_size=batch_size)

else:
    validation = True
    data_train, data_val = random_split(full_dataset, split_sizes)
    train_dataloader = DataLoader(data_train, shuffle=True, batch_size=batch_size)
    print(len(train_dataloader.dataset))
    val_dataloader = DataLoader(data_val, shuffle=False, batch_size=batch_size)
    print(len(val_dataloader.dataset))


device = "cuda:0" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

class Block(nn.Module):
    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):
        super(Block, self).__init__()
        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)
        self.bn3 = nn.BatchNorm2d(out_channels)
        self.dropout = nn.Dropout(0.6)
        self.relu = nn.ReLU()
        self.identity_downsample = identity_downsample

    def forward(self, x):
        # saving weights at beginning to reapply at end of block 
        identity = x

        # main block architecture - 2 conv layers with batch norm and relu
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.conv3(x)
        x = self.bn3(x)

        # dropout layer to help with overfitting
        x = self.dropout(x)

        # if there is a size mismatch, downsample identity before readding
        if self.identity_downsample is not None:
            identity = self.identity_downsample(identity)

        # reapply weights from beginning of block
        x += identity
        x = self.relu(x)
        return x


class Network(nn.Module):
    def __init__(self):
        super(Network, self).__init__()
        block=Block
        image_channels=1
        num_classes=4
        layers = [2, 2, 2]
        self.in_channels = 64

        # input layer
        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=5, stride=2, padding=3)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.dropout = nn.Dropout(0.75)

        # ResNetLayers
        self.layer1 = self.make_layers(block, layers[0], intermediate_channels=64, stride=1)
        self.layer2 = self.make_layers(block, layers[1], intermediate_channels=128, stride=2)
        self.layer3 = self.make_layers(block, layers[2], intermediate_channels=256, stride=2)

        # output layer
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(256, num_classes)

    def forward(self, x):
      # input layer fwding
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.dropout(x)

      # ResNet layers
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)

      # output layer
        x = self.avgpool(x)
        x = x.reshape(x.shape[0], -1)
        x = self.fc(x)
        return x

    # function to make resnet layers based on given parameters
    def make_layers(self, block, num_residual_blocks, intermediate_channels, stride):
        layers = []

        # used if size of identity is incompatible with output of block
        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels, kernel_size=1, stride=stride),
                                            nn.BatchNorm2d(intermediate_channels))
        layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride))
        self.in_channels = intermediate_channels # 256
        for i in range(num_residual_blocks - 1):
            layers.append(block(self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again
        return nn.Sequential(*layers)

net = Network()
# net = UNet(n_channels=1, n_classes=4)
model = net.to(device)
print(model)

optimizer = optim.Adam(net.parameters(), lr = 0.01)

loss_func = nn.CrossEntropyLoss()

num_epochs = 40

start = time.time()
best_accuracy = 0.0 

print("Start training...")
for epoch in range(1,num_epochs+1):
    total_train_loss = 0
    total_val_loss = 0
    total_images = 0
    total_correct = 0

    # Training
    for batch in train_dataloader:           # Load batch
        images_train, labels_train = batch
        optimizer.zero_grad()
        images_train = images_train.to(device, dtype=torch.float)
        labels_train = labels_train.type(torch.LongTensor)
        labels_train = labels_train.to(device)

        preds_train = model(images_train)             # Process batch

        train_loss = loss_func(preds_train, labels_train) # Calculate loss

        train_loss.backward()                 # Calculate gradients
        optimizer.step()                # Update weights
        total_train_loss += train_loss.item()

        if not validation:
            output = preds_train.argmax(dim=1)
            total_images += int(labels_train.size(0))
            total_correct += int(output.eq(labels_train).sum().item())

    # Get train loss
    train_loss = total_train_loss/len(train_dataloader) 

    # Validation
    if validation:
        with torch.no_grad():
            model.eval()
            for batch in val_dataloader:
                images_val, labels_val = batch
                images_val = images_val.to(device, dtype=torch.float)
                labels_val = labels_val.type(torch.LongTensor)
                labels_val = labels_val.to(device)

                preds_val = model(images_val)
                val_loss = loss_func(preds_val, labels_val) 
                total_val_loss += val_loss.item()

                output = preds_val.argmax(dim=1)
                total_images += int(labels_val.size(0))
                total_correct += int(output.eq(labels_val).sum().item())
            model.train()

        # Get val loss
        val_loss = total_val_loss/len(val_dataloader) 

    model_accuracy = total_correct / total_images

    if not validation:
        print(f"ep {epoch}, train loss: {train_loss:.2f}, Train Acc {model_accuracy*100:.2f}%")
    else:
        print(f"ep {epoch}, train loss: {train_loss:.2f}, val loss: {val_loss:.2f}, Val Acc {model_accuracy*100:.2f}%")

    # if epoch % 10 == 0:
    #     torch.save(net.state_dict(),'checkModel.pth')
    #     print("   Model saved to checkModel.pth")

    if model_accuracy > best_accuracy:
        torch.save(net.state_dict(),'savedModel.pth')
        print("\tModel saved to savedModel.pth")
        best_accuracy = model_accuracy 

    if epoch % 2 == 0:
        torch.save(net.state_dict(),'checkModel{}.pth'.format(epoch))
        print("   Model saved to checkModel.pth")

    sys.stdout.flush()

# torch.save(net.state_dict(),'savedModel.pth')
# print("   Model saved to savedModel.pth")

end = time.time()
print(f"\nTotal training time: {str(datetime.timedelta(seconds=end-start))}")

# Function to test the model
def test(path): 
    # Load the model that we saved at the end of the training loop 
    model = Network()
    print('testing with path: ', path)
    model.load_state_dict(torch.load(path)) 
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    print(f"Using {device} device")    
    model.to(device) 
    running_accuracy = 0 
    total = 0 

    with torch.no_grad(): 
        for data in test_dataloader: 
            images, outputs = data 
            outputs = outputs.to(device, dtype=torch.float32) 
            images = images.to(device, dtype=torch.float)
            predicted_outputs = model(images) 
            _, predicted = torch.max(predicted_outputs, 1) 
            total += outputs.size(0) 
            running_accuracy += (predicted == outputs).sum().item() 
        print('Accuracy of the model based on the test set of the inputs is: %d %%' % (100 * running_accuracy / total))   
        return (100 * running_accuracy / total)

if not use_full_dataset_to_train_and_val:
    start = time.time()

    accuracies = []
    epochs = []
    for i in range(2, num_epochs+1, 2):
        epochs.append(i)
        accuracies.append(test('checkModel{}.pth'.format(str(i))))
    plt.plot(epochs, accuracies)
    plt.title('Testing Acc vs. Epochs of Training')

    stats_directory = "stats/"
    if not os.path.exists(stats_directory):
        os.makedirs(stats_directory)

    plt.savefig(f'{stats_directory}/testingacc.png')

    end = time.time()
    print(f"\nTotal testing time: {str(datetime.timedelta(seconds=end-start))}")