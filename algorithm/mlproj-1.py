# -*- coding: utf-8 -*-
"""MLproj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SBfvNizBpxdYqOpQjhNgueqIp8kBAWdV
"""

import torch
import torchvision
import sklearn.metrics as metrics
import numpy as np
import sys
import matplotlib.pyplot as plt
import statistics
import torch.optim as optim
from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split
import torch.nn as nn
import math
import torchvision.transforms as tt
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold


class TransformTensorDataset(Dataset):
    """TensorDataset with support of transforms.
    """
    def __init__(self, tensors, transform=None):
        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)
        self.tensors = tensors
        self.transform = transform

    def __getitem__(self, index):
        x = self.tensors[0][index]

        if self.transform:
            x = self.transform(x)

        y = self.tensors[1][index]

        return x, y

    def __len__(self):
        return self.tensors[0].size(0)



device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

class Block(nn.Module):
    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):
        super(Block, self).__init__()
        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)
        self.bn3 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()
        self.identity_downsample = identity_downsample

    def forward(self, x):
        # saving weights at beginning to reapply at end of block
        identity = x

        # main block architecture - 2 conv layers with batch norm and relu
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.conv3(x)
        x = self.bn3(x)

        # if there is a size mismatch, downsample identity before readding
        if self.identity_downsample is not None:
            identity = self.identity_downsample(identity)

        # reapply weights from beginning of block
        x += identity
        x = self.relu(x)
        return x


class Network(nn.Module):
    def __init__(self):
        super(Network, self).__init__()
        block=Block
        image_channels=1
        num_classes=5
        layers = [2, 2, 2]
        self.in_channels = 64

        # input layer
        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=5, stride=2, padding=3)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # ResNetLayers
        self.layer1 = self.make_layers(block, layers[0], intermediate_channels=64, stride=1)
        self.layer2 = self.make_layers(block, layers[1], intermediate_channels=128, stride=2)
        self.layer3 = self.make_layers(block, layers[2], intermediate_channels=256, stride=2)

        # output layer
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(256, num_classes)

    def forward(self, x):
      # input layer fwding
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

      # ResNet layers
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)

      # output layer
        x = self.avgpool(x)
        x = x.reshape(x.shape[0], -1)
        x = self.fc(x)
        return x

    # function to make resnet layers based on given parameters
    def make_layers(self, block, num_residual_blocks, intermediate_channels, stride):
        layers = []

        # used if size of identity is incompatible with output of block
        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels, kernel_size=1, stride=stride),
                                            nn.BatchNorm2d(intermediate_channels))
        layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride))
        self.in_channels = intermediate_channels # 256
        for i in range(num_residual_blocks - 1):
            layers.append(block(self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again
        return nn.Sequential(*layers)



X_test = np.load("X_test.npy")
print(X_test.shape)

X_test = np.transpose(X_test, (0,3,1,2))
X_test_0 = torchvision.transforms.functional.rgb_to_grayscale(torch.tensor(X_test))

X_test_scaled = nn.functional.interpolate(torch.tensor(X_test_0), scale_factor=0.25)
print(X_test_scaled.shape)

# save("X_test_scaled.npy".format(str(i)), X_test_scaled)

data = np.load("X_test_scaled.npy")
test_dataloader = DataLoader(data, shuffle=False)

def test(path):
    # Load the model that we saved at the end of the training loop
    model = Network()
    print('testing with path: ', path)
    model.load_state_dict(torch.load(path))
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # print(f"Using {device} device")
    model.to(device)
    running_accuracy = 0
    total = 0

    with torch.no_grad():
        predictions = []
        for data in test_dataloader:
            images, outputs = data
            outputs = outputs.to(device, dtype=torch.float32)
            images = images.to(device, dtype=torch.float)
            predicted_outputs = model(images)
            _, predicted = torch.max(predicted_outputs, 1)
            predictions.append(predicted)
            total += outputs.size(0)
            running_accuracy += (predicted == outputs).sum().item()

        print('Accuracy of the model based on the test set of the inputs is: %d %%' % (100 * running_accuracy / total))
        return predictions

predictions = test('ModResNet_lr_01_bs_200.pth')
np.save('testPredictions.npy', predictions)
